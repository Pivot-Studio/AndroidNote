- **什么是高并发呢？**
- 多个进程或线程同时（或者说在同一段时间内）访问同一资源会产生并发问题
- ## 访问人数过多时引起的高并发解决方案
- **初期解决方案**
- 系统或服务器级别的解决方案
  
  1)增大服务器的CPU。
  
  2)增加内存条。
  
  3)增加硬盘个数，对硬盘做Raid5。
  
  4)换掉免费的Tomcat，使用商用weblogic(美国Oracle公司出品的)
  
  5)增加到二块网卡。
  
  6)聘请系统架构师优化Linux内核
  
  7)甚至花高价直接购买高性能服务器
  
  随着业务的不断增加，服务器性能很快又到达瓶颈
  
  2.应用级别的解决方案
  
  1)网页HTML 静态化（需要CMS项目支持）
  
  2)图片服务器分离（常用解决方案）
  
  3)缓存（常用解决方案） 上上策为分布式缓存
  
  4)镜像（下载较多）
  
  随着业务的不断增加，服务器性能很快又到达瓶颈
  
  **能否增加服务器数量？**
  
  解决办法：增加App服务器
- **随之出现更多问题**
- 问题1;用户访问IP多了，怎么解决？
- 问题2：数据库出现瓶颈 怎么办？
- **由上面的问题引出终极解决方案—— 负载均衡**
- 由于目前现有网络的各个核心部分随着业务量的提高，访问量和数据流量的快速增长，其处理能力和计算强度也相应地增大，使得单一的服务器设备根本无法承担。在此情况下，如果扔掉现有设备去做大量的硬件升级，这样将造成现有资源的浪费，而且如果再面临下一次业务量的提升时，这又将导致再一次硬件升级的高额成本投入，甚至性能再卓越的设备也不能满足当前业务量增长的需求。
- 针对此情况而衍生出来的一种廉价有效透明的方法以扩展现有网络设备和服务器的带宽、增加吞吐量、加强网络数据处理能力、提高网络的灵活性和可用性的技术就是负载均衡（Load Balance）。
- ## 数据库高并发的解决方案
- **大数据量**
  
  **场景：**我说的大数据量处理是指同时需要对数据进行检索查询，同时有高并发的增删改操作。
  
  **大数据的处理:**例如腾讯，盛大，动辄数以亿计的帐号,怎么能这么快呢， 于是找到了互联网现在对数据处理的发展。
  
  **对于大数据量处理，如果是互联网处理的话，一般分为下面阶段：**
  
  第一阶段，所有数据都装入一个数据库，当数据量大了肯定就会出现问题，就像刚刚说的查询，于是想办法
  
  第二阶段，那时肯定想做缓存机制，确实可以，如加上缓存Memcached，但缓存也是治标不治本，数据量太大了也是不行，于是
  
  第三阶段，master-slave模式，进行主从数据库，master提供写，slave进行读，这个适合于有写造成数据库卡的方法，还是不行，于是
  
  第四阶段，垂直分库，这个意义还是不大，于是
  
  第五阶段，进行水平分库，这个不错，记得以前从兴也是按这个分时间水平分库，其实可以分的更细点估计效果更好
  
  **那么数据库出现瓶颈怎么办呢？**
  
  以Mysql为例：
- 对Mysql进行优化（重点讲解）
- 缓存,主流缓存Memcached，redis…
- mysql读写分离 + 主从复制
- Oracle
- Oracle读写分离 + 主从复制
- Oracle Partition 分区
- Oracle RAC集群（终级解决方案）此方案：非常贵，即使是淘宝，京东这样的大公司，也是很难受的。
  
  **解决方案有：MySql 主从复制与读写分离**
  
  MySQL主从复制(Master-Slave)与读写分离(MySQL-Proxy)实践
  
  Mysql作为目前世界上使用最广泛的免费数据库，相信所有从事系统运维的工程师都一定接触过。但在实际的生产环境中，由单台Mysql作为独立的数据库是完全不能满足实际需求的，无论是在安全性，高可用性以及高并发等各个方面。
  
  因此，一般来说都是通过 主从复制（Master-Slave）的方式来同步数据，再通过读写分离（MySQL-Proxy）来提升数据库的并发负载能力 这样的方案来进行部署与实施的。